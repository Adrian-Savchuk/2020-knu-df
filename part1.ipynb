{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "part1",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAY1VTg5x9qq",
        "colab_type": "text"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Madm9Eoix9qs",
        "colab_type": "text"
      },
      "source": [
        "Below is an implementation of the [LeNet](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) architecture for the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-3hUt5fx9qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP8oh2X2x9q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om3arARpx9rD",
        "colab_type": "code",
        "outputId": "e3a67f4e-f681-481e-b2f5-ba93be470cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCsFe_hUx9rK",
        "colab_type": "text"
      },
      "source": [
        "Of note: This notebook uses only a single GPU.\n",
        "PyTorch can run models on several GPU, try to search how to specify several GPUs and create several devices.\n",
        "model = Net().to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5b8f1a0d-893f-4fcf-c67d-34206cb9b272",
        "id": "VS8lj7EyhAzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model = Net().to(device)\n",
        "model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kpNVQWvx9ro",
        "colab_type": "text"
      },
      "source": [
        "## Master way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Uhkn9Lx9rq",
        "colab_type": "text"
      },
      "source": [
        "Or inspect code for training a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bfUgVkYx9rs",
        "colab_type": "code",
        "outputId": "ba3c595e-36e5-4bd7-9a96-121626e6755f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist', \n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=128, shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 19514008.92it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 329596.14it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 4949946.98it/s]                           \n",
            "8192it [00:00, 131482.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yGfvkGBx9rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Stochastic Gradient Descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_5F2MpXx9r8",
        "colab_type": "code",
        "outputId": "2aa41e82-6670-4450-c801-fcb9b5c9594c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "epoch_num = 20\n",
        "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Remember a line with model.to(device)?\n",
        "        # It moves a model to a GPU and PyTorch expects that\n",
        "        # input data also will be on the GPU where the model resides\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # Calculate the error between model predictins and actual labels\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Initiate backward propagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[Epoch {epoch + 1}: batch {i + 1}] loss: {running_loss / 200}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1: batch 200] loss: 2.300912083387375\n",
            "[Epoch 1: batch 400] loss: 2.292199219465256\n",
            "[Epoch 2: batch 200] loss: 2.25081999540329\n",
            "[Epoch 2: batch 400] loss: 2.0716172575950624\n",
            "[Epoch 3: batch 200] loss: 1.3769828242063522\n",
            "[Epoch 3: batch 400] loss: 1.0425387924909593\n",
            "[Epoch 4: batch 200] loss: 0.8467708942294121\n",
            "[Epoch 4: batch 400] loss: 0.7572080254554748\n",
            "[Epoch 5: batch 200] loss: 0.6820179295539855\n",
            "[Epoch 5: batch 400] loss: 0.6440729618072509\n",
            "[Epoch 6: batch 200] loss: 0.5963554908335209\n",
            "[Epoch 6: batch 400] loss: 0.5670346532762051\n",
            "[Epoch 7: batch 200] loss: 0.5378463572263718\n",
            "[Epoch 7: batch 400] loss: 0.5207896269857883\n",
            "[Epoch 8: batch 200] loss: 0.48948692962527274\n",
            "[Epoch 8: batch 400] loss: 0.4784983342885971\n",
            "[Epoch 9: batch 200] loss: 0.46169598400592804\n",
            "[Epoch 9: batch 400] loss: 0.451797526627779\n",
            "[Epoch 10: batch 200] loss: 0.42996211543679236\n",
            "[Epoch 10: batch 400] loss: 0.419955270588398\n",
            "[Epoch 11: batch 200] loss: 0.4116348556429148\n",
            "[Epoch 11: batch 400] loss: 0.39717978194355963\n",
            "[Epoch 12: batch 200] loss: 0.3802236182242632\n",
            "[Epoch 12: batch 400] loss: 0.3864768723398447\n",
            "[Epoch 13: batch 200] loss: 0.3704136288911104\n",
            "[Epoch 13: batch 400] loss: 0.3573545540869236\n",
            "[Epoch 14: batch 200] loss: 0.3530959239602089\n",
            "[Epoch 14: batch 400] loss: 0.346542906910181\n",
            "[Epoch 15: batch 200] loss: 0.33699531003832817\n",
            "[Epoch 15: batch 400] loss: 0.3403421124815941\n",
            "[Epoch 16: batch 200] loss: 0.32870297953486444\n",
            "[Epoch 16: batch 400] loss: 0.314975431188941\n",
            "[Epoch 17: batch 200] loss: 0.3173708520829678\n",
            "[Epoch 17: batch 400] loss: 0.3205490233004093\n",
            "[Epoch 18: batch 200] loss: 0.3097262958437204\n",
            "[Epoch 18: batch 400] loss: 0.31546306602656843\n",
            "[Epoch 19: batch 200] loss: 0.31238609686493873\n",
            "[Epoch 19: batch 400] loss: 0.29189856462180613\n",
            "[Epoch 20: batch 200] loss: 0.2988623908534646\n",
            "[Epoch 20: batch 400] loss: 0.29853696525096896\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKi9iapjx9sF",
        "colab_type": "text"
      },
      "source": [
        "Let's check how accurate is our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypy0EeMex9sH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = datasets.MNIST('./mnist',\n",
        "                           train=False,\n",
        "                           download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                           ]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC2576cDx9sO",
        "colab_type": "code",
        "outputId": "6b9d64ae-91c4-4bfc-e76b-83fa29c76881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Prevent training\n",
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "avg_loss = 0.0\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "   \n",
        "    output = model(inputs)\n",
        "    avg_loss += criterion(output, labels).sum()\n",
        "    \n",
        "    # tensor.detach() creates a tensor that shares storage with tensor that does not require grad.\n",
        "    # It detaches the output from the computational graph.\n",
        "    # So no gradient will be backpropagated along this variable.\n",
        "    pred = output.detach().max(1)[1]\n",
        "    total_correct += pred.eq(labels.view_as(pred)).sum()\n",
        "\n",
        "avg_loss /= len(data_test)\n",
        "avg_loss = avg_loss.detach().cpu().item()\n",
        "accuracy = float(total_correct) / len(data_test)\n",
        "print(f'Test Avg. Loss: {avg_loss}, Accuracy: {accuracy * 100}%')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Avg. Loss: 0.00040681404061615467, Accuracy: 96.74000000000001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqse8UZex9sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model state for re-use\n",
        "my_awesome_model = 'my-lenet.pth'\n",
        "torch.save(model.state_dict(), my_awesome_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPLpykihx9se",
        "colab_type": "text"
      },
      "source": [
        "**End of training code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDOpLtDTx9sj",
        "colab_type": "text"
      },
      "source": [
        "**FGSM Attack**\n",
        "The fgsm_attack function takes three inputs: image is the original clean image (x), epsilon is the pixel-wise perturbation amount (ϵ), and data_grad is gradient of the loss w.r.t the input image.\n",
        "\n",
        "The function then creates perturbed image as\n",
        "\n",
        "$$\\text{perturbed image} = image + epsilon * sign(gradient) = x + ϵ ∗ sign(∇xJ(θ,x,y))$$\n",
        "The fgsm_attack function takes three inputs: image is the original clean image (x), epsilon is the pixel-wise perturbation amount (ϵ), and data_grad is gradient of the loss w.r.t the input image.\n",
        "\n",
        "The function then creates perturbed image as\n",
        "\n",
        "$$\\text{perturbed image} = image + epsilon * sign(gradient) = x + ϵ ∗ sign(∇xJ(θ,x,y))$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5yIFALNx9sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # FGSM attack code\n",
        "# def fgsm_attack(image, epsilon, data_grad):\n",
        "#     # Collect the element-wise sign of the data gradient\n",
        "#     sign_data_grad = data_grad.sign()\n",
        "    \n",
        "#     # Create the perturbed image by adjusting each pixel of the input image\n",
        "#     perturbed_image = image + epsilon * sign_data_grad\n",
        "    \n",
        "#     # Adding clipping to maintain [0,1] range\n",
        "#     perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    \n",
        "#     # Return the perturbed image\n",
        "#     return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V92vJAbx9sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist',\n",
        "                   train=False,\n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ5wvIbDx9s5",
        "colab_type": "text"
      },
      "source": [
        "Test function performs a full test step on the MNIST test set and reports a final accuracy.\n",
        "\n",
        "For each sample in the test set, the function computes the gradient of the loss w.r.t the input data (data_grad),  creates a perturbed image with fgsm_attack (perturbed_data), then checks to see if the perturbed example is adversarial. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRY5_peqx9s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def test( model, device, test_loader, epsilon ):\n",
        "\n",
        "#     # Accuracy counter\n",
        "#     correct = 0\n",
        "#     adv_examples = []\n",
        "\n",
        "#     # Loop over all examples in test set\n",
        "#     for data, target in test_loader:\n",
        "\n",
        "#         # Send the data and label to the device\n",
        "#         data, target = data.to(device), target.to(device)\n",
        "\n",
        "#         # Set requires_grad attribute of tensor. Important for Attack\n",
        "#         data.requires_grad = True\n",
        "\n",
        "#         # Forward pass the data through the model\n",
        "#         output = model(data)\n",
        "#         init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "#         # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "#         if init_pred.item() != target.item():\n",
        "#             continue\n",
        "\n",
        "#         # Calculate the loss - Negative Log Likehood\n",
        "#         # Loosely explained at https://medium.com/deeplearningmadeeasy/negative-log-likelihood-6bd79b55d8b6\n",
        "#         loss = F.nll_loss(output, target)\n",
        "\n",
        "#         # Zero all existing gradients\n",
        "#         model.zero_grad()\n",
        "\n",
        "#         # Calculate gradients of model in backward pass\n",
        "#         loss.backward()\n",
        "\n",
        "#         # Collect datagrad\n",
        "#         data_grad = data.grad.data\n",
        "\n",
        "#         # Call FGSM Attack\n",
        "#         perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "#         # Re-classify the perturbed image\n",
        "#         output = model(perturbed_data)\n",
        "\n",
        "#         # Check for success\n",
        "#         final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "#         if final_pred.item() == target.item():\n",
        "#             correct += 1\n",
        "#             # Special case for saving 0 epsilon examples\n",
        "#             if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "#                 adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "#                 adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "#         else:\n",
        "#             # Save some adv examples for visualization later\n",
        "#             if len(adv_examples) < 5:\n",
        "#                 adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "#                 adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "#     # Calculate final accuracy for this epsilon\n",
        "#     final_acc = correct/float(len(test_loader))\n",
        "#     print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "#     # Return the accuracy and an adversarial example\n",
        "#     return final_acc, adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COz8UBZxx9tE",
        "colab_type": "text"
      },
      "source": [
        "# Let's attack!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FVzquqax9tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracies = []\n",
        "# examples = []\n",
        "\n",
        "# # Epsilon 0 means no attack at all\n",
        "# epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "\n",
        "# # Run test for each epsilon\n",
        "# for eps in epsilons:\n",
        "#     acc, ex = test(model, device, test_loader, eps)\n",
        "#     accuracies.append(acc)\n",
        "#     examples.append(ex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9E2gH87x9tN",
        "colab_type": "text"
      },
      "source": [
        "The first result is the accuracy versus epsilon plot.\n",
        "\n",
        "As epsilon increases we expect the test accuracy to decrease and it actually does. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JynJHjARx9tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.figure(figsize=(5,5))\n",
        "# plt.plot(epsilons, accuracies, \"*-\")\n",
        "# plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "# plt.xticks(np.arange(0, epsilons[-1] + 0.05, step=0.05))\n",
        "# plt.title(\"Accuracy vs Epsilon\")\n",
        "# plt.xlabel(\"Epsilon\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzkrQViNx9tV",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmLTL2bsx9tY",
        "colab_type": "text"
      },
      "source": [
        "There is a tradeoff between accuracy degredation and perceptibility that an attacker must consider.  \n",
        "\n",
        "Below are some examples of successful adversarial examples at each epsilon value.  \n",
        "Each row of the plot shows a different epsilon value. The first row is the ϵ=0 examples which represent the original “clean” images with no perturbation. The title of each image shows the “original classification -> adversarial classification.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLCYtbRbx9tZ",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tougzz4nx9tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#    # Plot several examples of adversarial samples at each epsilon\n",
        "# cnt = 0\n",
        "# plt.figure(figsize=(8,10))\n",
        "\n",
        "# for i in range(len(epsilons)):\n",
        "#     for j in range(len(examples[i])):\n",
        "#         cnt += 1\n",
        "#         plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "#         plt.xticks([], [])\n",
        "#         plt.yticks([], [])\n",
        "#         if j == 0:\n",
        "#             plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "#         orig, adv, ex = examples[i][j]\n",
        "#         plt.title(\"True {} -> Adv {}\".format(orig, adv))\n",
        "#         plt.imshow(ex, cmap=\"gray\")\n",
        "        \n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH672P_Xx9th",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUUIA0Fjx9tj",
        "colab_type": "text"
      },
      "source": [
        "Take a closer look at how we calculated gradient. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up5PKUgFx9tk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b06849eb-6b63-4702-d283-f9d75e47761f"
      },
      "source": [
        "epsilon = epsilons[2]\n",
        "for data, target in test_loader:  \n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data.requires_grad = True\n",
        "    \n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "   \n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    data_grad = data.grad.data\n",
        "    perturbed_data = fgsm_attack(data, epsilon, data_grad)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-db8acc88c041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epsilons' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2KKi7mHx9tr",
        "colab_type": "text"
      },
      "source": [
        "The second parameter to the loss function is a true label of the current image. After that gradient is used for perturbation generation.\n",
        "<br>\n",
        "<br>\n",
        "Remember that gradient is obtained for the whole image\n",
        "pixels, namely gradient shape is equal to the image shape.  \n",
        "In our case it's (28, 28, 1). So **each pixel gets own perturbation**.\n",
        "\n",
        "Now recall how we apply gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtYWY3RNx9tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sign_data_grad = data_grad.sign()\n",
        "# perturbed_image = img + epsilon * sign_data_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDiD-QjVx9t0",
        "colab_type": "text"
      },
      "source": [
        "We add the scaled gradient to the original image. The result of this action is misclassification, but we don't know what label gain higher confidence. This is a case of *untargeted misclassification*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNClv0dx9t2",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQxKHzBCx9t4",
        "colab_type": "text"
      },
      "source": [
        "*Targeted misclassification* implies that you add perturbation and model predicts one of the possible labels but not the correct one. For achieving this you should take gradient with respect to you selected label.\n",
        "\n",
        "But it's not enough. Also, you should subtract scaled gradient instead of adding. Doing this we actually perform gradient descent on the loss function surface in direction to the target class. Remember that we want **to minimize** loss function with respect to **selected class**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCdC_WzNx9t5",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01iL6zCix9t7",
        "colab_type": "text"
      },
      "source": [
        "# PRACTICUM TASK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHizwGox9t-",
        "colab_type": "text"
      },
      "source": [
        "1 - For each class select 10 images not from this class. Perform attack to move selected images to this class. for each class select image with highest confidence.\n",
        "    \n",
        "Best sample is the one with higher confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsh8DOUXx9uA",
        "colab_type": "text"
      },
      "source": [
        "2 - Try different epsilons for one selected class and collect the number of iterations required to achieve success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbeNTwJrx9uD",
        "colab_type": "text"
      },
      "source": [
        "3* OPTIONAL - make attacks using a model trained on Cifar10 obtained from the previous task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6TRdZVPhGvv",
        "colab_type": "text"
      },
      "source": [
        "# Let's rock!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHacWdobhczK",
        "colab_type": "text"
      },
      "source": [
        "importing foolbox and torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ5iTmBRC8gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9Y54DyTCSXa",
        "colab_type": "text"
      },
      "source": [
        "If it's necessary - install foolbox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSHzsUxhCYsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install foolbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6uiJeG_x9uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import foolbox\n",
        "from foolbox.models import PyTorchModel\n",
        "from foolbox.attacks import L2BasicIterativeAttack, FGSM\n",
        "from foolbox.criteria import Misclassification, ConfidentMisclassification, TargetClassProbability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqbhZrHKhcM7",
        "colab_type": "text"
      },
      "source": [
        "Loader and criterion. We have chosen class of digit 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qHKO617hrls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist', \n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=128, shuffle=True)\n",
        "\n",
        "criterion = TargetClassProbability(2, 0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZTkONoNEs2o",
        "colab_type": "text"
      },
      "source": [
        "Visualization if it is necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5QWxfkwDWAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # visualize data\n",
        "# fig=plt.figure(figsize=(16, 8))\n",
        "# data, label = next(iter(loader))\n",
        "\n",
        "# for i in range(1, 51):\n",
        "#     img = data[i][0]\n",
        "#     fig.add_subplot(5, 10, i)\n",
        "#     plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
        "# plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etr9DZBWRjL3",
        "colab_type": "text"
      },
      "source": [
        "Creating a dictionary, which has keys = digits and values are ten pictures, which contains these digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhvZ6Bx_HuSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "digit_images = defaultdict(list)\n",
        "data, label = next(iter(loader))\n",
        "# label = np.array(lebel)\n",
        "\n",
        "for digit in range(10):\n",
        "  i = 0\n",
        "  while (len(digit_images[digit])) != 10 and i < len(data):\n",
        "    if label[i] == digit:\n",
        "      digit_images[digit].append(data[i][0])\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaUhRWYBqOrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "fb_model = PyTorchModel(\n",
        "    model, \n",
        "    bounds=(-4, +4), \n",
        "    num_classes=1000,\n",
        "    channel_axis=1,\n",
        ")\n",
        "attack = FGSM(\n",
        "    model=fb_model,\n",
        "    criterion=criterion\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtM9WR_uGjW5",
        "colab_type": "text"
      },
      "source": [
        "#HERE IS AN `AssertionError`!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUblQLNXR8NF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "72e389e5-bf02-442e-ae7b-74dff8eeef83"
      },
      "source": [
        "normalized_image = digit_images[7][0].unsqueeze(0).to(device)\n",
        "normalized_image = normalized_image.unsqueeze(0).to(device)\n",
        "normalized_image.size()\n",
        "prediction = model(normalized_image)[0]\n",
        "predicted_class = prediction.argmax(-1).cpu().numpy()\n",
        "print(f\"Predicted class {int(predicted_class)} : {'7'}\")\n",
        "print(f\"Probability: {torch.softmax(prediction, -1)[predicted_class]:.4f}\")\n",
        "\n",
        "# First we need to move our input from torch to numpy array, as it required by FoolBox\n",
        "normalazed_input_numpy = normalized_image.cpu().numpy()\n",
        "\n",
        "# Than we need to do a little modification to the predicted class\n",
        "# Namely move it to array of shape [batch_size], in our case [1]\n",
        "predicted_labels = np.array([int(predicted_class)])\n",
        "# And finaly we can generate new image provided starting point and true label\n",
        "new_images = attack(normalazed_input_numpy, labels=predicted_labels)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class 7 : 7\n",
            "Probability: 0.9979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-880abcb9ad77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# And finaly we can generate new image provided starting point and true label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mnew_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalazed_input_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, labels, unpack, individual_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mindividual_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindividual_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/batching.py\u001b[0m in \u001b[0;36mrun_parallel\u001b[0;34m(create_attack_fn, model, criterion, inputs, labels, distance, threshold, verbose, individual_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     ]\n\u001b[1;32m    243\u001b[0m     attacks = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/batching.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     ]\n\u001b[1;32m    243\u001b[0m     attacks = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/v1/adversarial.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, criterion, unperturbed, original_class, distance, threshold, verbose)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# check if the original input is already adversarial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_unperturbed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unperturbed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/adversarial.py\u001b[0m in \u001b[0;36m_check_unperturbed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# for now, we use the non-yielding implementation in the super-class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# TODO: add support for batching this first call as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdversarial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Adversarial__unperturbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopAttack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# if a threshold is specified and the unperturbed input is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/v1/adversarial.py\u001b[0m in \u001b[0;36mforward_one\u001b[0;34m(self, x, strict, return_details)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_prediction_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         is_adversarial, is_best, distance = self.__is_adversarial(\n\u001b[1;32m    314\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/models/base.py\u001b[0m in \u001b[0;36mforward_one\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/foolbox/models/pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}