{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "part1",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAY1VTg5x9qq",
        "colab_type": "text"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Madm9Eoix9qs",
        "colab_type": "text"
      },
      "source": [
        "Below is an implementation of the [LeNet](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) architecture for the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-3hUt5fx9qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP8oh2X2x9q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyBG37-rP5XH",
        "colab_type": "text"
      },
      "source": [
        "Fact checking!) Maybe were not so attentive and missed that we didn't turn CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om3arARpx9rD",
        "colab_type": "code",
        "outputId": "c70350b2-1754-4534-b62e-20e68c23307e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCsFe_hUx9rK",
        "colab_type": "text"
      },
      "source": [
        "Of note: This notebook uses only a single GPU.\n",
        "PyTorch can run models on several GPU, try to search how to specify several GPUs and create several devices.\n",
        "model = Net().to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kpNVQWvx9ro",
        "colab_type": "text"
      },
      "source": [
        "## Master way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Uhkn9Lx9rq",
        "colab_type": "text"
      },
      "source": [
        "Or inspect code for training a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bfUgVkYx9rs",
        "colab_type": "code",
        "outputId": "a1e3952b-a9aa-42bd-d063-cbd5166cb8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                   datasets.MNIST('./mnist', \n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([transforms.ToTensor(),])),\n",
        "                   batch_size=128, shuffle=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Stochastic Gradient Descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "epoch_num = 20\n",
        "\n",
        "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Remember a line with model.to(device)?\n",
        "        # It moves a model to a GPU and PyTorch expects that\n",
        "        # input data also will be on the GPU where the model resides\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # Calculate the error between model predictins and actual labels\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Initiate backward propagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[Epoch {epoch + 1}: batch {i + 1}] loss: {running_loss / 200}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/9912422 [00:00<01:33, 106130.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 22147396.77it/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 319083.77it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5292248.25it/s]                           \n",
            "8192it [00:00, 127029.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "[Epoch 1: batch 200] loss: 2.303384546041489\n",
            "[Epoch 1: batch 400] loss: 2.2937665462493895\n",
            "[Epoch 2: batch 200] loss: 2.2570377480983734\n",
            "[Epoch 2: batch 400] loss: 2.07907123029232\n",
            "[Epoch 3: batch 200] loss: 1.3508539617061615\n",
            "[Epoch 3: batch 400] loss: 1.0321911495923997\n",
            "[Epoch 4: batch 200] loss: 0.8401314169168472\n",
            "[Epoch 4: batch 400] loss: 0.768484505712986\n",
            "[Epoch 5: batch 200] loss: 0.7086541709303856\n",
            "[Epoch 5: batch 400] loss: 0.6567149890959263\n",
            "[Epoch 6: batch 200] loss: 0.6153358618915081\n",
            "[Epoch 6: batch 400] loss: 0.5968232147395611\n",
            "[Epoch 7: batch 200] loss: 0.5755457104742527\n",
            "[Epoch 7: batch 400] loss: 0.5391014856100083\n",
            "[Epoch 8: batch 200] loss: 0.5344913145899772\n",
            "[Epoch 8: batch 400] loss: 0.49288954317569733\n",
            "[Epoch 9: batch 200] loss: 0.49392173618078233\n",
            "[Epoch 9: batch 400] loss: 0.48002193227410317\n",
            "[Epoch 10: batch 200] loss: 0.46512583404779434\n",
            "[Epoch 10: batch 400] loss: 0.45408244743943216\n",
            "[Epoch 11: batch 200] loss: 0.44023317024111747\n",
            "[Epoch 11: batch 400] loss: 0.44295482739806175\n",
            "[Epoch 12: batch 200] loss: 0.43109129056334494\n",
            "[Epoch 12: batch 400] loss: 0.4241783950477839\n",
            "[Epoch 13: batch 200] loss: 0.4137244687974453\n",
            "[Epoch 13: batch 400] loss: 0.3977593305706978\n",
            "[Epoch 14: batch 200] loss: 0.38381073243916036\n",
            "[Epoch 14: batch 400] loss: 0.39717524774372576\n",
            "[Epoch 15: batch 200] loss: 0.379703563824296\n",
            "[Epoch 15: batch 400] loss: 0.38094156675040725\n",
            "[Epoch 16: batch 200] loss: 0.37201626136898996\n",
            "[Epoch 16: batch 400] loss: 0.3597855585068464\n",
            "[Epoch 17: batch 200] loss: 0.3613147749751806\n",
            "[Epoch 17: batch 400] loss: 0.35895124286413194\n",
            "[Epoch 18: batch 200] loss: 0.3535962425172329\n",
            "[Epoch 18: batch 400] loss: 0.34430938921868803\n",
            "[Epoch 19: batch 200] loss: 0.34822052672505377\n",
            "[Epoch 19: batch 400] loss: 0.33370880588889124\n",
            "[Epoch 20: batch 200] loss: 0.3386033895611763\n",
            "[Epoch 20: batch 400] loss: 0.32970608107745647\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKi9iapjx9sF",
        "colab_type": "text"
      },
      "source": [
        "Let's check how accurate is our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypy0EeMex9sH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f116ec1-2647-4a4f-964d-6e12fb6fa005"
      },
      "source": [
        "data_test = datasets.MNIST('./mnist',\n",
        "                           train=False,\n",
        "                           download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                           ]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=256)\n",
        "# Prevent training\n",
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "avg_loss = 0.0\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "   \n",
        "    output = model(inputs)\n",
        "    avg_loss += criterion(output, labels).sum()\n",
        "    \n",
        "    # tensor.detach() creates a tensor that shares storage with tensor that does not require grad.\n",
        "    # It detaches the output from the computational graph.\n",
        "    # So no gradient will be backpropagated along this variable.\n",
        "    pred = output.detach().max(1)[1]\n",
        "    total_correct += pred.eq(labels.view_as(pred)).sum()\n",
        "\n",
        "avg_loss /= len(data_test)\n",
        "avg_loss = avg_loss.detach().cpu().item()\n",
        "accuracy = float(total_correct) / len(data_test)\n",
        "print(f'Test Avg. Loss: {avg_loss}, Accuracy: {accuracy * 100}%')\n",
        "\n",
        "# Save model state for re-use\n",
        "my_awesome_model = 'my-lenet.pth'\n",
        "torch.save(model.state_dict(), my_awesome_model)\n",
        "# End of training code"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Avg. Loss: 0.0004768944636452943, Accuracy: 96.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V92vJAbx9sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist',\n",
        "                   train=False,\n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ5wvIbDx9s5",
        "colab_type": "text"
      },
      "source": [
        "Test function performs a full test step on the MNIST test set and reports a final accuracy.\n",
        "\n",
        "For each sample in the test set, the function computes the gradient of the loss w.r.t the input data (data_grad),  creates a perturbed image with fgsm_attack (perturbed_data), then checks to see if the perturbed example is adversarial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01iL6zCix9t7",
        "colab_type": "text"
      },
      "source": [
        "# PRACTICUM TASK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHizwGox9t-",
        "colab_type": "text"
      },
      "source": [
        "1 - For each class select 10 images not from this class. Perform attack to move selected images to this class. for each class select image with highest confidence.\n",
        "    \n",
        "Best sample is the one with higher confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsh8DOUXx9uA",
        "colab_type": "text"
      },
      "source": [
        "2 - Try different epsilons for one selected class and collect the number of iterations required to achieve success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbeNTwJrx9uD",
        "colab_type": "text"
      },
      "source": [
        "3* OPTIONAL - make attacks using a model trained on Cifar10 obtained from the previous task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6TRdZVPhGvv",
        "colab_type": "text"
      },
      "source": [
        "# Let's rock!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHacWdobhczK",
        "colab_type": "text"
      },
      "source": [
        "importing foolbox and torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ5iTmBRC8gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9Y54DyTCSXa",
        "colab_type": "text"
      },
      "source": [
        "If it's necessary - install foolbox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSHzsUxhCYsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "2b939515-a161-4330-c71f-42fbe8a136d2"
      },
      "source": [
        "pip install foolbox"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting foolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/3f/cee46491ba9546d8c7bf14e18a4ecbdae411ca3d2e2ccdb227aad6de1782/foolbox-2.3.0.tar.gz (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox) (42.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from foolbox) (2.21.0)\n",
            "Collecting GitPython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/8c/4543981439d23c4ff65b2e62dddd767ebc84a8e664a9b67e840d1e2730d3/GitPython-3.0.5-py3-none-any.whl (455kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (1.24.3)\n",
            "Collecting gitdb2>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 13.2MB/s \n",
            "\u001b[?25hCollecting smmap2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: foolbox\n",
            "  Building wheel for foolbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for foolbox: filename=foolbox-2.3.0-cp36-none-any.whl size=1926239 sha256=779c71961443d697afff9890147e291288b66d084f60953a47e6f9be4ae2edec\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/e4/a4/b6a9e61a9729c442383d774328091f69d9235268401a1c9524\n",
            "Successfully built foolbox\n",
            "Installing collected packages: smmap2, gitdb2, GitPython, foolbox\n",
            "Successfully installed GitPython-3.0.5 foolbox-2.3.0 gitdb2-2.0.6 smmap2-2.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6uiJeG_x9uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import foolbox\n",
        "from foolbox.models import PyTorchModel\n",
        "from foolbox.attacks import L2BasicIterativeAttack, FGSM\n",
        "from foolbox.criteria import Misclassification, ConfidentMisclassification, TargetClassProbability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqbhZrHKhcM7",
        "colab_type": "text"
      },
      "source": [
        "Loader and criterion. We have chosen class of digit 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qHKO617hrls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist', \n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=128, shuffle=True)\n",
        "\n",
        "criterion = TargetClassProbability(2, 0.90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZTkONoNEs2o",
        "colab_type": "text"
      },
      "source": [
        "Visualization if it is necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etr9DZBWRjL3",
        "colab_type": "text"
      },
      "source": [
        "Creating a dictionary, which has keys = digits and values are ten pictures, which contains these digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhvZ6Bx_HuSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "digit_images = defaultdict(list)\n",
        "data, label = next(iter(loader))\n",
        "# label = np.array(lebel)\n",
        "\n",
        "for digit in range(10):\n",
        "  i = 0\n",
        "  while (len(digit_images[digit])) != 10 and i < len(data):\n",
        "    if label[i] == digit:\n",
        "      digit_images[digit].append(data[i][0])\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD69614RnCUp",
        "colab_type": "text"
      },
      "source": [
        "Functions for adversarials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaUhRWYBqOrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "fb_model = PyTorchModel(\n",
        "    model, \n",
        "    bounds=(-4, +4), \n",
        "    num_classes=10,\n",
        "    channel_axis=1,\n",
        ")\n",
        " \n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        # resize image to 28 pixels in width and hight\n",
        "        transforms.Resize((28, 28)),\n",
        "        \n",
        "        # transorm \"Image\" object to \"tensor\" onject. Used when working with PIL.Image\n",
        "        transforms.ToTensor(),\n",
        "        \n",
        "        # Normalize image per chanel\n",
        "        # transforms.Normalize(\n",
        "        #     mean=[0.485, 0.456, 0.406],\n",
        "        #     std=[0.229, 0.224, 0.225]\n",
        "        # )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqmJsIeXR8NY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def restore_image(image):\n",
        "    # Move chanel axis [3, 299, 299] -> [299, 299, 3]\n",
        "    new_image = np.rollaxis(np.rollaxis((image), 2), 2)\n",
        "    \n",
        "    # Multiply by std and add mean\n",
        "    # new_image = (new_image * [0.229, 0.224, 0.225]) + [0.485, 0.456, 0.406]\n",
        "    \n",
        "    # Move from range 0-1 to the range 0-255\n",
        "    new_image = new_image * 255\n",
        "    \n",
        "    # Make sure to remove all values that lower that 0 or higher than 255\n",
        "    # as it not valid images\n",
        "    new_image = np.clip(new_image, 0, 255)\n",
        "    \n",
        "    # Put image to the \"byte\" format. \n",
        "    # That`s required by PIL.Image to be abble to restore image from numpy array\n",
        "    new_image = new_image.astype(np.uint8)\n",
        "    return new_image[:,:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk-S8cWdR8N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_adversarial(foolbox_model, attack, selected_criterion, image):\n",
        "    attack = attack(\n",
        "        model=foolbox_model,\n",
        "        criterion=selected_criterion\n",
        "    )\n",
        "    normalized_image = image.unsqueeze(0).to(device)\n",
        "    ########### I added  another unsqueeze, because it caused an error ########\n",
        "    normalized_image = normalized_image.unsqueeze(0).to(device)\n",
        "    prediction = model(normalized_image)[0]\n",
        "    predicted_class = prediction.argmax(-1).cpu().numpy()\n",
        "    \n",
        "    normalazed_input_numpy = normalized_image.cpu().numpy()\n",
        "    predicted_labels = np.array([int(predicted_class)])\n",
        "\n",
        "    new_images = attack(normalazed_input_numpy, labels=predicted_labels)\n",
        "    \n",
        "    restored_numpy_array = restore_image(new_images[0])\n",
        "    restored_image = Image.fromarray(restored_numpy_array)\n",
        "    return restored_image\n",
        "\n",
        "def print_prediction(image, label):\n",
        "  normalized_image = transform(image).unsqueeze(0).to(device)\n",
        "  # print(normalized_image.size())\n",
        "  # normalized_image = normalized_image.unsqueeze(0).to(device)\n",
        "  prediction = model(normalized_image)[0]\n",
        "  predicted_class = prediction.argmax(-1).cpu().numpy()\n",
        "  probability = torch.softmax(prediction, -1)[predicted_class] * 100\n",
        "  print(f\"Predicted class {int(predicted_class)} : real {label}\")\n",
        "  print(f\"Probability: {probability:.3f}\")\n",
        "  return probability\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Qab3ZS3w9f",
        "colab_type": "text"
      },
      "source": [
        "#Attacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQs1Xmob3zh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aaefad0d-4995-4c8e-e5e7-f4b52f98c3e6"
      },
      "source": [
        "# pic = digit_images[j][1]\n",
        "cnt = 0\n",
        "predics = np.zeros(10)\n",
        "examples = []\n",
        "plt.figure(figsize=(20,20))\n",
        "for digit in range(10):\n",
        "  for j in range(10):\n",
        "    if j == digit:\n",
        "      pass\n",
        "    else:\n",
        "      adv_image = generate_adversarial(\n",
        "          fb_model, \n",
        "          L2BasicIterativeAttack,\n",
        "          TargetClassProbability(digit, 0.95), \n",
        "          digit_images[j][1]\n",
        "      )\n",
        "      a = print_prediction(adv_image, j)\n",
        "      if predics[digit] <= a:\n",
        "        predics[digit] = a\n",
        "        pic = initial_image\n",
        "  examples.append(pic)\n",
        "\n",
        "# print_prediction(adv_image, 5)\n",
        "# initial_image = adv_image.resize((150, 150))\n",
        "# initial_image\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class 0 : real 1\n",
            "Probability: 84.875\n",
            "Predicted class 0 : real 2\n",
            "Probability: 79.707\n",
            "Predicted class 0 : real 3\n",
            "Probability: 86.019\n",
            "Predicted class 0 : real 4\n",
            "Probability: 67.955\n",
            "Predicted class 0 : real 5\n",
            "Probability: 75.046\n",
            "Predicted class 0 : real 6\n",
            "Probability: 76.025\n",
            "Predicted class 0 : real 7\n",
            "Probability: 75.271\n",
            "Predicted class 0 : real 8\n",
            "Probability: 79.879\n",
            "Predicted class 0 : real 9\n",
            "Probability: 78.643\n",
            "Predicted class 1 : real 0\n",
            "Probability: 89.757\n",
            "Predicted class 1 : real 2\n",
            "Probability: 76.360\n",
            "Predicted class 1 : real 3\n",
            "Probability: 56.129\n",
            "Predicted class 1 : real 4\n",
            "Probability: 62.599\n",
            "Predicted class 1 : real 5\n",
            "Probability: 79.797\n",
            "Predicted class 6 : real 6\n",
            "Probability: 79.021\n",
            "Predicted class 1 : real 7\n",
            "Probability: 88.770\n",
            "Predicted class 1 : real 8\n",
            "Probability: 55.656\n",
            "Predicted class 1 : real 9\n",
            "Probability: 78.143\n",
            "Predicted class 2 : real 0\n",
            "Probability: 81.946\n",
            "Predicted class 2 : real 1\n",
            "Probability: 86.925\n",
            "Predicted class 2 : real 3\n",
            "Probability: 79.544\n",
            "Predicted class 2 : real 4\n",
            "Probability: 58.784\n",
            "Predicted class 2 : real 5\n",
            "Probability: 70.018\n",
            "Predicted class 2 : real 6\n",
            "Probability: 79.355\n",
            "Predicted class 2 : real 7\n",
            "Probability: 83.999\n",
            "Predicted class 2 : real 8\n",
            "Probability: 83.144\n",
            "Predicted class 2 : real 9\n",
            "Probability: 77.668\n",
            "Predicted class 3 : real 0\n",
            "Probability: 73.027\n",
            "Predicted class 3 : real 1\n",
            "Probability: 77.420\n",
            "Predicted class 3 : real 2\n",
            "Probability: 73.485\n",
            "Predicted class 3 : real 4\n",
            "Probability: 69.327\n",
            "Predicted class 3 : real 5\n",
            "Probability: 85.933\n",
            "Predicted class 3 : real 6\n",
            "Probability: 55.847\n",
            "Predicted class 3 : real 7\n",
            "Probability: 84.384\n",
            "Predicted class 3 : real 8\n",
            "Probability: 73.752\n",
            "Predicted class 3 : real 9\n",
            "Probability: 74.469\n",
            "Predicted class 4 : real 0\n",
            "Probability: 63.570\n",
            "Predicted class 4 : real 1\n",
            "Probability: 80.086\n",
            "Predicted class 4 : real 2\n",
            "Probability: 76.339\n",
            "Predicted class 3 : real 3\n",
            "Probability: 60.501\n",
            "Predicted class 4 : real 5\n",
            "Probability: 60.892\n",
            "Predicted class 4 : real 6\n",
            "Probability: 52.490\n",
            "Predicted class 4 : real 7\n",
            "Probability: 70.676\n",
            "Predicted class 4 : real 8\n",
            "Probability: 72.688\n",
            "Predicted class 4 : real 9\n",
            "Probability: 83.242\n",
            "Predicted class 5 : real 0\n",
            "Probability: 67.874\n",
            "Predicted class 5 : real 1\n",
            "Probability: 74.610\n",
            "Predicted class 5 : real 2\n",
            "Probability: 65.889\n",
            "Predicted class 5 : real 3\n",
            "Probability: 77.392\n",
            "Predicted class 5 : real 4\n",
            "Probability: 53.141\n",
            "Predicted class 6 : real 6\n",
            "Probability: 46.825\n",
            "Predicted class 5 : real 7\n",
            "Probability: 75.440\n",
            "Predicted class 5 : real 8\n",
            "Probability: 67.862\n",
            "Predicted class 5 : real 9\n",
            "Probability: 69.767\n",
            "Predicted class 6 : real 0\n",
            "Probability: 76.520\n",
            "Predicted class 6 : real 1\n",
            "Probability: 85.567\n",
            "Predicted class 6 : real 2\n",
            "Probability: 87.016\n",
            "Predicted class 6 : real 3\n",
            "Probability: 83.452\n",
            "Predicted class 6 : real 4\n",
            "Probability: 82.322\n",
            "Predicted class 6 : real 5\n",
            "Probability: 68.064\n",
            "Predicted class 6 : real 7\n",
            "Probability: 69.967\n",
            "Predicted class 6 : real 8\n",
            "Probability: 75.337\n",
            "Predicted class 6 : real 9\n",
            "Probability: 65.374\n",
            "Predicted class 7 : real 0\n",
            "Probability: 60.550\n",
            "Predicted class 7 : real 1\n",
            "Probability: 85.522\n",
            "Predicted class 7 : real 2\n",
            "Probability: 71.574\n",
            "Predicted class 7 : real 3\n",
            "Probability: 61.416\n",
            "Predicted class 4 : real 4\n",
            "Probability: 63.584\n",
            "Predicted class 7 : real 5\n",
            "Probability: 79.769\n",
            "Predicted class 7 : real 6\n",
            "Probability: 70.907\n",
            "Predicted class 7 : real 8\n",
            "Probability: 80.894\n",
            "Predicted class 7 : real 9\n",
            "Probability: 58.944\n",
            "Predicted class 8 : real 0\n",
            "Probability: 75.550\n",
            "Predicted class 8 : real 1\n",
            "Probability: 85.739\n",
            "Predicted class 8 : real 2\n",
            "Probability: 66.099\n",
            "Predicted class 8 : real 3\n",
            "Probability: 86.553\n",
            "Predicted class 8 : real 4\n",
            "Probability: 49.467\n",
            "Predicted class 8 : real 5\n",
            "Probability: 84.073\n",
            "Predicted class 8 : real 6\n",
            "Probability: 54.517\n",
            "Predicted class 8 : real 7\n",
            "Probability: 81.593\n",
            "Predicted class 8 : real 9\n",
            "Probability: 80.936\n",
            "Predicted class 9 : real 0\n",
            "Probability: 80.230\n",
            "Predicted class 9 : real 1\n",
            "Probability: 87.638\n",
            "Predicted class 9 : real 2\n",
            "Probability: 85.890\n",
            "Predicted class 9 : real 3\n",
            "Probability: 79.408\n",
            "Predicted class 9 : real 4\n",
            "Probability: 56.600\n",
            "Predicted class 9 : real 5\n",
            "Probability: 77.763\n",
            "Predicted class 9 : real 6\n",
            "Probability: 66.884\n",
            "Predicted class 9 : real 7\n",
            "Probability: 87.160\n",
            "Predicted class 9 : real 8\n",
            "Probability: 84.680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmqiTk-jqKE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "5ad27444-dbf6-4ce8-ce9a-94cccdc3b024"
      },
      "source": [
        "cnt = 0\n",
        "plt.figure(figsize=(8,10))\n",
        "\n",
        "# for i in range(10):\n",
        "for j in range(len(examples)):\n",
        "    cnt += 1\n",
        "    plt.subplot(10,len(examples),cnt)\n",
        "    plt.xticks([], [])\n",
        "    plt.yticks([], [])\n",
        "    if j == 0:\n",
        "        # plt.ylabel(\"Eps: {}\".format(10), fontsize=14)\n",
        "        pass\n",
        "    # orig, adv, ex = examples[i][j]\n",
        "    plt.title(\"True {} -> Adv {}\".format('a', j))\n",
        "    plt.imshow(examples[j], cmap=\"gray\")\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAABHCAYAAAB8pI9AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}