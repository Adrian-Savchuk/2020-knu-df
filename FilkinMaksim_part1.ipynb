{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "FilkinMaksim_part1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjRTcnVNrcL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epe2aAiLrcME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtMg0FbfrcMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjSa4GPHrcMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTfTgjeYrcM-",
        "colab_type": "text"
      },
      "source": [
        "## Master way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj6r85-_rcNF",
        "colab_type": "text"
      },
      "source": [
        "Or inspect code for training a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uANyAYB0rcNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist', \n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=128, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQfwfPEDrcNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Stochastic Gradient Descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oi3M65prcNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_num = 20\n",
        "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Remember a line with model.to(device)?\n",
        "        # It moves a model to a GPU and PyTorch expects that\n",
        "        # input data also will be on the GPU where the model resides\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # Calculate the error between model predictins and actual labels\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Initiate backward propagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[Epoch {epoch + 1}: batch {i + 1}] loss: {running_loss / 200}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HL-vcblrcNh",
        "colab_type": "text"
      },
      "source": [
        "Let's check how accurate is our network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DUXrPdmrcNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = datasets.MNIST('./mnist',\n",
        "                           train=False,\n",
        "                           download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                           ]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfHX_orLrcNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prevent training\n",
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "avg_loss = 0.0\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "   \n",
        "    output = model(inputs)\n",
        "    avg_loss += criterion(output, labels).sum()\n",
        "    \n",
        "    # tensor.detach() creates a tensor that shares storage with tensor that does not require grad.\n",
        "    # It detaches the output from the computational graph.\n",
        "    # So no gradient will be backpropagated along this variable.\n",
        "    pred = output.detach().max(1)[1]\n",
        "    total_correct += pred.eq(labels.view_as(pred)).sum()\n",
        "\n",
        "avg_loss /= len(data_test)\n",
        "avg_loss = avg_loss.detach().cpu().item()\n",
        "accuracy = float(total_correct) / len(data_test)\n",
        "print(f'Test Avg. Loss: {avg_loss}, Accuracy: {accuracy}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqeRiG9ArcN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model state for re-use\n",
        "my_awesome_model = 'my-lenet.pth'\n",
        "torch.save(model.state_dict(), my_awesome_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSLPfm_XrcOG",
        "colab_type": "text"
      },
      "source": [
        "**FGSM Attack**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_gLEUAarcON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    \n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    \n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    \n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGkqGTCorcOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./mnist',\n",
        "                   train=False,\n",
        "                   download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAhYACxUrcQH",
        "colab_type": "text"
      },
      "source": [
        "# PRACTICUM TASK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1FXWSy5rcQI",
        "colab_type": "text"
      },
      "source": [
        "1 - For each class select 10 images not from this class. Perform attack to move selected images to this class. for each class select image with highest confidence.\n",
        "    \n",
        "Best sample is the one with higher confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6cM4HiQrcQM",
        "colab_type": "text"
      },
      "source": [
        "2 - Try different epsilons for one selected class and collect the number of iterations required to achieve success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXqi1kY5rcQO",
        "colab_type": "text"
      },
      "source": [
        "3* OPTIONAL - make attacks using a model trained on Cifar10 obtained from the previous task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jhGYWqdt9eF",
        "colab_type": "text"
      },
      "source": [
        "**Task 1**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_PWV2qUuBdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test( model, device, test_loader, epsilon, iterative, target_label):\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        if iterative:\n",
        "            num_iterations = 10\n",
        "        else:\n",
        "            num_iterations = 1\n",
        "        for _ in range(num_iterations):\n",
        "            data.requires_grad = True\n",
        "            output = model(data)\n",
        "            init_pred = output.max(1, keepdim=True)[1]\n",
        "            if init_pred.item() != target.item():\n",
        "                continue\n",
        "            loss = -F.nll_loss(output, torch.tensor([target_label]).to(device))\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            data_grad = data.grad.data\n",
        "            data = fgsm_attack(data, epsilon, data_grad)\n",
        "            data = data.detach()\n",
        "        perturbed_data = data\n",
        "        output = model(perturbed_data)\n",
        "        final_pred = output.max(1, keepdim=True)[1]\n",
        "        if final_pred.item() != target.item():\n",
        "            if final_pred.item() == target_label:\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (target.item(), final_pred.item(), adv_ex) )\n",
        "            if len(adv_examples) == 10:\n",
        "                break \n",
        "    return adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGBNTdEpvlPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Adversarial_Attacks_For_Number(val):\n",
        "    accuracies = []\n",
        "    examples = []\n",
        "\n",
        "    # Epsilon 0 means no attack at all\n",
        "    epsilons = [.05, .1, .15, .2, .25, .3]\n",
        "\n",
        "    # Run test for each epsilon\n",
        "    for eps in epsilons:\n",
        "        ex = test(model, device, test_loader, eps, True, val)\n",
        "        examples.append(ex)\n",
        "           # Plot several examples of adversarial samples at each epsilon\n",
        "    cnt = 0\n",
        "    plt.figure(figsize=(16,20))\n",
        "\n",
        "    for i in range(len(epsilons)):\n",
        "        for j in range(len(examples[i])):\n",
        "            cnt += 1\n",
        "            plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "            plt.xticks([], [])\n",
        "            plt.yticks([], [])\n",
        "            if j == 0:\n",
        "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "            orig, adv, ex = examples[i][j]\n",
        "            plt.title(\"True {} -> Adv {}\".format(orig, adv))\n",
        "            plt.imshow(ex, cmap=\"gray\")\n",
        "            \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH9-VHLqB-A3",
        "colab_type": "text"
      },
      "source": [
        "**Task 2**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UK8j0VxCBU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyvkaWyCDT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_D58oFOCEBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmNUsp9oCEj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v9dEPcdCFsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JXSQkKhCGSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hkElgJgCGzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no8T5xEnCHUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_sRCcVnCH0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQvaIc1VCISk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adversarial_Attacks_For_Number(9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTLV1yPdCJCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}